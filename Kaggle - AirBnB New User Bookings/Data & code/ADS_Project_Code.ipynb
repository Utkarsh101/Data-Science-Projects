{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from time import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "df_train = pd.read_csv('train_users_2.csv')\n",
    "df_test = pd.read_csv('test_users.csv')\n",
    "labels = df_train['country_destination'].values\n",
    "df_train = df_train.drop(['country_destination'], axis=1)\n",
    "id_test = df_test['id']\n",
    "piv_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a DataFrame with train+test data\n",
    "df_all = pd.concat((df_train, df_test), axis=0, ignore_index=True)\n",
    "#Removing id and date_first_booking\n",
    "df_all = df_all.drop(['id', 'date_first_booking'], axis=1)\n",
    "#Filling nan\n",
    "df_all = df_all.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all['date_account_created'] =  pd.to_datetime(df_all['date_account_created'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting day, month & year from date_account_created\n",
    "df_all['dac_year'] = df_all['date_account_created'].dt.year\n",
    "df_all['dac_month'] = df_all['date_account_created'].dt.month\n",
    "df_all['dac_day'] = df_all['date_account_created'].dt.day\n",
    "df_all = df_all.drop(['date_account_created'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting day, month & year from timestamp_first_active\n",
    "\n",
    "def trim_fraction(text):\n",
    "    if '.0' in text:\n",
    "        return text[:text.rfind('.0')]\n",
    "    return text\n",
    "\n",
    "list1 = []\n",
    "for i in range(0,len(df_all)):\n",
    "    list1.append(df_all.timestamp_first_active[i].astype(str))\n",
    "    \n",
    "list2 = []\n",
    "for i in list1:\n",
    "    list2.append(trim_fraction(i))\n",
    "\n",
    "df_tfa = pd.DataFrame({\"tfa\":list2})\n",
    "\n",
    "\n",
    "tfa = np.vstack(\n",
    "    df_tfa.tfa.apply(\n",
    "        lambda x: list(map(int, [x[:4], x[4:6], x[6:8],\n",
    "                                 x[8:10], x[10:12],\n",
    "                                 x[12:14]]))\n",
    "        ).values)\n",
    "\n",
    "df_all['tfa_year'] = tfa[:,0]\n",
    "df_all['tfa_month'] = tfa[:,1]\n",
    "df_all['tfa_day'] = tfa[:,2]\n",
    "df_all = df_all.drop(['timestamp_first_active'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Age\n",
    "\n",
    "av = df_all.age.values\n",
    "df_all['age'] = np.where(np.logical_or(av<14, av>132), -1, av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot-encoding features\n",
    "\n",
    "ohe_feats = ['gender', 'signup_method', 'signup_flow', 'language', \n",
    "             'affiliate_channel', 'affiliate_provider', \n",
    "             'first_affiliate_tracked', 'signup_app', \n",
    "             'first_device_type', 'first_browser']\n",
    "for f in ohe_feats:\n",
    "    df_all_dummy = pd.get_dummies(df_all[f], prefix=f)\n",
    "    df_all = df_all.drop([f], axis=1)\n",
    "    df_all = pd.concat((df_all, df_all_dummy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting train and test\n",
    "\n",
    "X = df_all.iloc[:piv_train,:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)   \n",
    "test = df_all.iloc[piv_train:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv(classifier, X_train, y_train):\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    now = time()\n",
    "    log(\"Crossvalidating \" + classifier_name + \"...\")\n",
    "    accuracy = [cross_val_score(classifier, X_train, y_train, cv=8, n_jobs=-1)]\n",
    "    log(\"Crosvalidation completed in {0}s\".format(time() - now))\n",
    "    log(\"Accuracy: \" + str(accuracy[0]))\n",
    "    log(\"Average accuracy: \" + str(np.array(accuracy[0]).mean()))\n",
    "    log(\"===============================================\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forrest Classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.7, stratify=y)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rf_acc = cv(RandomForestClassifier(),X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "y_pred = rf.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.7, stratify=y)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gbm_acc = cv(GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1),X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "gbm.fit(X, y)\n",
    "y_pred = nb.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ADA Boost Classifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.7, stratify=y)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, AdaBoostClassifier(n_estimators=100, base_estimator= DecisionTreeClassifier(),learning_rate=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ada_acc = cv(AdaBoostClassifier(n_estimators=100, base_estimator= DecisionTreeClassifier(),learning_rate=1),X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier(n_estimators=100, base_estimator= DecisionTreeClassifier(),learning_rate=1)\n",
    "ada.fit(X, y)\n",
    "y_pred = nb.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.7, stratify=y)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, XGBClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb_acc = cv(XGBClassifier(),X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier\n",
    "  \n",
    "xgb = XGBClassifier(max_depth=6, learning_rate=0.3, n_estimators=25,\n",
    "                    objective='multi:softprob', subsample=0.5, colsample_bytree=0.5, seed=0)\n",
    "xgb.fit(X, y)\n",
    "y_pred = xgb.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning the XGBoost Classifier parameters \n",
    "\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            log(\"Model with rank: {0}\".format(i))\n",
    "            log(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate],\n",
    "                results['std_test_score'][candidate]))\n",
    "            log(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            log(\"\")\n",
    "\n",
    "def best_fit(X_train, y_train, n_iter=5):\n",
    "    \n",
    "    parameters = {\n",
    "        \"n_estimators\":[25,103,201, 403],\n",
    "        \"max_depth\":[3,10,15, 30],\n",
    "        \"objective\":[\"multi:softmax\",'multi:softprob'],\n",
    "        \"learning_rate\":[0.05, 0.1, 0.15, 0.3]\n",
    "    }\n",
    "\n",
    "    rand_search = RandomizedSearchCV(XGBoostClassifier(seed=seed),param_distributions=parameters,\n",
    "                                     n_iter=n_iter,scoring=\"accuracy\",\n",
    "                                     n_jobs=-1,cv=8)\n",
    "\n",
    "    import time as ttt\n",
    "    now = time()\n",
    "    log(ttt.ctime())\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    report(rand_search.cv_results_, 10)\n",
    "    log(ttt.ctime())\n",
    "    log(\"Search took: \" + str(time() - now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_fit(data_model.iloc[:, 1:], data_model.iloc[:, 0], n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking the 5 classes with highest probabilities\n",
    "\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(id_test)):\n",
    "    idx = id_test[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(y_pred[i])[::-1])[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate submission\n",
    "\n",
    "sub = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "sub.to_csv('submission_xgb.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
